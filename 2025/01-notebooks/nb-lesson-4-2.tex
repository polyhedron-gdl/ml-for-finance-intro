% Default to the notebook output style

    


% Inherit from the specified cell style.

\documentclass{article}


    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{soul}      % strikethrough (\st) support for pandoc >= 3.0.0
    \usepackage{mathrsfs}
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{nb-lesson-4-2}
    
    
    
    
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \section{Model Selection and Hyperparameter
Tuning}\label{model-selection-and-hyperparameter-tuning}

    This notebook is based on

Sebastian Raschka and Vahid Mirjalili \textbf{Python Machine Learning},
Third Edition 2019, Packt Publishing

\textbf{Chapter 6 - Learning Best Practices for Model Evaluation and
Hyperparameter Tuning}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{c+c1}{\PYZsh{} Import necessary libraries}
         \PY{k+kn}{import} \PY{n+nn}{numpy}             \PY{k}{as} \PY{n+nn}{np}   \PY{c+c1}{\PYZsh{} For numerical operations}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}  \PY{c+c1}{\PYZsh{} For plotting}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets}         \PY{k+kn}{import} \PY{n}{make\PYZus{}classification}     \PY{c+c1}{\PYZsh{} To create synthetic classification data}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets}         \PY{k+kn}{import} \PY{n}{make\PYZus{}regression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble}         \PY{k+kn}{import} \PY{n}{RandomForestClassifier}  \PY{c+c1}{\PYZsh{} Random Forest Classifier}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection}  \PY{k+kn}{import} \PY{n}{learning\PYZus{}curve}          \PY{c+c1}{\PYZsh{} For computing learning curves}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection}  \PY{k+kn}{import} \PY{n}{validation\PYZus{}curve}        \PY{c+c1}{\PYZsh{} For computing validation curves}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection}  \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}        \PY{c+c1}{\PYZsh{} For splitting the dataset into training and test sets}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model}     \PY{k+kn}{import} \PY{n}{LinearRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree}             \PY{k+kn}{import} \PY{n}{DecisionTreeRegressor}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k+kn}{import} \PY{n}{Image}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
\end{Verbatim}

    \subsection{Introduction}\label{introduction}

Model selection is a fundamental step in the development of machine
learning solutions. It involves choosing the most appropriate algorithm
and hyperparameters to achieve the best generalization performance on
unseen data. Selecting an appropriate model is not merely about choosing
the most complex or powerful algorithm but about balancing bias and
variance while ensuring the model is neither underfitting nor
overfitting the data.

\subsubsection{Theoretical Foundations}\label{theoretical-foundations}

The process of model selection requires evaluating multiple candidate
models based on their ability to generalize. A key consideration is the
\textbf{bias-variance tradeoff}: models with high bias tend to underfit
the data, failing to capture its complexity, whereas models with high
variance tend to overfit, capturing noise rather than meaningful
patterns. The goal is to identify a model that achieves an optimal
balance between these two extremes.

A common approach to model selection relies on
\textbf{cross-validation}, a technique that partitions the data into
training and validation subsets multiple times to assess the model's
performance robustly. \textbf{K-fold cross-validation} is one of the
most widely used methods, where the dataset is divided into \emph{k}
subsets, training occurs on \emph{k-1} folds, and the remaining fold is
used for validation. This process repeats \emph{k} times, and the
results are averaged to estimate the model's performance.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../05\PYZhy{}pictures/lesson\PYZhy{}4\PYZhy{}2\PYZus{}pic\PYZus{}0.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{800}\PY{p}{)} 
\end{Verbatim}

    \emph{Source: Raschka S. et al.~- Python Machine Learning - Chapter 6
(see Reference and Credits section)}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../05\PYZhy{}pictures/lesson\PYZhy{}4\PYZhy{}2\PYZus{}pic\PYZus{}1.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{800}\PY{p}{)} 
\end{Verbatim}

    \emph{Source: Raschka S. et al.~- Python Machine Learning - Chapter 6
(see Reference and Credits section)}

    \subsubsection{Practical Model Selection Using
Python}\label{practical-model-selection-using-python}

To illustrate model selection in practice, we can compare different
machine learning models using cross-validation. Consider the task of
predicting housing prices using the \texttt{scikit-learn} library.

    \begin{quote}
\textbf{NOTE: What Does cross\_val\_score Do?} - It splits the dataset
into multiple subsets (or ``folds''). - It trains the model on some
folds and tests it on the remaining fold. - It repeats this process
multiple times, ensuring that every data point gets to be in a test set
once. - It returns an array of scores, one for each fold, which can then
be averaged to get a final evaluation.

For Example, if cv=5, the dataset is split into 5 equal parts (folds):

\begin{itemize}
\tightlist
\item
  Train on folds 1-4, test on fold 5
\item
  Train on folds 1, 2, 3, 5, test on fold 4
\item
  Train on folds 1, 2, 4, 5, test on fold 3
\item
  Train on folds 1, 3, 4, 5, test on fold 2
\item
  Train on folds 2-5, test on fold 1
\end{itemize}

Each fold gets a chance to be in the test set once, making the
evaluation more robust.
\end{quote}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{time}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k+kn}{import} \PY{n}{SVR}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{fetch\PYZus{}california\PYZus{}housing}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{RandomForestRegressor}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LinearRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{,} \PY{n}{cross\PYZus{}val\PYZus{}score}
         \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k+kn}{import} \PY{n}{tqdm}  \PY{c+c1}{\PYZsh{} Library for progress bar}
         
         \PY{c+c1}{\PYZsh{} Load the California housing dataset}
         \PY{c+c1}{\PYZsh{} This dataset contains housing data for California, with features such as median income, house age, etc.}
         \PY{n}{housing} \PY{o}{=} \PY{n}{fetch\PYZus{}california\PYZus{}housing}\PY{p}{(}\PY{p}{)}
         \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{housing}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{housing}\PY{o}{.}\PY{n}{target}  \PY{c+c1}{\PYZsh{} Features (X) and target variable (y)}
         
         \PY{c+c1}{\PYZsh{} Split data into training and test sets (80\PYZpc{} training, 20\PYZpc{} test)}
         \PY{c+c1}{\PYZsh{} This helps evaluate model generalization on unseen data}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Define different models to compare}
         \PY{c+c1}{\PYZsh{} We include Linear Regression, Random Forest, and Support Vector Machine}
         \PY{n}{models} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{p}{,}
             \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Forest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{:} \PY{n}{RandomForestRegressor}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}\PY{p}{,}
         \PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Dictionary to store cross\PYZhy{}validation results}
         \PY{n}{results} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Measure execution time for model selection process}
         \PY{n}{start\PYZus{}time} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Evaluate models using cross\PYZhy{}validation with a progress bar}
         \PY{k}{for} \PY{n}{name}\PY{p}{,} \PY{n}{model} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{models}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{desc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Evaluating models}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Perform 5\PYZhy{}fold cross\PYZhy{}validation}
             \PY{n}{scores} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Store the mean R\PYZca{}2 score for each model}
             \PY{n}{results}\PY{p}{[}\PY{n}{name}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{scores}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Measure total execution time}
         \PY{n}{end\PYZus{}time} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
         \PY{n}{execution\PYZus{}time} \PY{o}{=} \PY{n}{end\PYZus{}time} \PY{o}{\PYZhy{}} \PY{n}{start\PYZus{}time}
         
         \PY{c+c1}{\PYZsh{} Convert results dictionary to DataFrame for better readability}
         \PY{n}{results\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{results}\PY{o}{.}\PY{n}{items}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{R\PYZca{}2 Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Print results}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{results\PYZus{}df}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Print execution time}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+sa}{f}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Total execution time: }\PY{l+s+si}{\PYZob{}}\PY{n}{execution\PYZus{}time}\PY{l+s+si}{:}\PY{l+s+s2}{.2f}\PY{l+s+si}{\PYZcb{}}\PY{l+s+s2}{ seconds}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Optional: Visualize the results}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{results}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{results}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mean R\PYZca{}2 Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Model Performance Comparison}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Evaluating models: 100\%|█████████████████████████████████████████████████████████████████| 2/2 [01:31<00:00, 45.54s/it]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
               Model  R\^{}2 Score
0  Linear Regression   0.611484
1      Random Forest   0.804153
Total execution time: 91.08 seconds

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_11_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In this example, two different models --- \textbf{Linear Regression} and
\textbf{Random Forest} --- are evaluated using 5-fold cross-validation.
The performance of each model is measured using the coefficient of
determination (R² score), which indicates how well the model explains
the variance in the target variable.

\subsubsection{Interpretation of
Results}\label{interpretation-of-results}

After executing the above script, we obtain R² scores for each model,
allowing us to compare their generalization ability. If one model
consistently achieves a higher score across validation folds, it
suggests a better fit to the data. However, model selection is not
solely about achieving the highest validation score; considerations such
as interpretability, computational efficiency, and robustness to new
data also play a crucial role.

For instance, if the dataset is small and interpretability is important,
a linear regression model might be preferable due to its simplicity.
Conversely, if prediction accuracy is the priority and computational
resources permit, an ensemble model like Random Forest may be the best
choice.

\subsubsection{Hyperparameter Tuning in Model
Selection}\label{hyperparameter-tuning-in-model-selection}

Beyond selecting the best algorithm, adjusting hyperparameters is
essential for optimizing model performance. This process, known as
\textbf{hyperparameter tuning}, can be automated using techniques like
\textbf{grid search} and \textbf{random search}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.model\_selection }\ImportTok{import}\NormalTok{ GridSearchCV}

\CommentTok{\# Define hyperparameter grid for Random Forest}
\NormalTok{param\_grid }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{\textquotesingle{}n\_estimators\textquotesingle{}}\NormalTok{: [}\DecValTok{50}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{],}
    \StringTok{\textquotesingle{}max\_depth\textquotesingle{}}\NormalTok{: [}\VariableTok{None}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{]}
\NormalTok{\}}

\CommentTok{\# Perform grid search}
\NormalTok{grid\_search }\OperatorTok{=}\NormalTok{ GridSearchCV(RandomForestRegressor(random\_state}\OperatorTok{=}\DecValTok{42}\NormalTok{), param\_grid, cv}\OperatorTok{=}\DecValTok{5}\NormalTok{, scoring}\OperatorTok{=}\StringTok{\textquotesingle{}r2\textquotesingle{}}\NormalTok{)}
\NormalTok{grid\_search.fit(X\_train, y\_train)}

\CommentTok{\# Display best parameters}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best Parameters:"}\NormalTok{, grid\_search.best\_params\_)}
\end{Highlighting}
\end{Shaded}

This script searches for the optimal combination of hyperparameters for
a Random Forest model using \textbf{GridSearchCV}, which systematically
evaluates different parameter settings and selects the combination
yielding the best cross-validation performance.

Model selection is a critical aspect of machine learning that extends
beyond merely choosing an algorithm. It involves balancing complexity,
generalization ability, and computational efficiency. Techniques such as
cross-validation provide reliable estimates of model performance, while
hyperparameter tuning further refines the selected model. By integrating
these techniques, practitioners can systematically approach model
selection to achieve robust and interpretable predictive solutions.

    \subsubsection{A Quick Remind about
Pipelines}\label{a-quick-remind-about-pipelines}

Scikit-learn \textbf{pipelines} provide a streamlined way to chain
multiple preprocessing steps and a machine learning model into a single
workflow. This makes code cleaner, ensures that transformations are
correctly applied to both training and test data, and simplifies
hyperparameter tuning.

\textbf{Basic Structure of a Pipeline}

A pipeline consists of a sequence of transformations (e.g., scaling,
encoding) followed by a final estimator (e.g., a regression or
classification model). The pipeline ensures that all preprocessing steps
are applied consistently.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../05\PYZhy{}pictures/lesson\PYZhy{}4\PYZhy{}2\PYZus{}pic\PYZus{}2.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{600}\PY{p}{)} 
\end{Verbatim}

    \emph{Source: Raschka S. et al.~- Python Machine Learning - Chapter 6
(see Reference and Credits section)}

    \textbf{Why Use Pipelines?}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Prevents data leakage}: Ensures preprocessing steps are only
  fitted on training data and applied consistently to test data.
\item
  \textbf{Code clarity}: Organizes multiple steps in a structured
  manner.
\item
  \textbf{Hyperparameter tuning}: Easily integrates with
  \texttt{GridSearchCV} or \texttt{RandomizedSearchCV} for optimization.
\end{enumerate}

Pipelines are especially useful for handling complex workflows,
including feature selection, transformations, and model training, in a
consistent and reproducible manner.

    \subsection{Learning Curve}\label{learning-curve}

    \subsubsection{Introduction}\label{introduction}

When selecting a machine learning model, one of the critical
considerations is understanding how the model's performance evolves as
it is exposed to more training data. This concept is best captured
through \textbf{learning curves}, which illustrate the relationship
between model performance (e.g., error rate or accuracy) and the size of
the training dataset. Learning curves provide crucial insights into
underfitting, overfitting, and the expected benefits of acquiring
additional data.

\subsubsection{Theoretical Foundation}\label{theoretical-foundation}

A learning curve is a graphical representation of how a model's error
metrics change with increasing training data. Typically, two curves are
plotted:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Training Error Curve}: This represents the error of the model
  on the training dataset. Initially, with a small amount of data, the
  training error is low because the model can fit the limited number of
  points easily. As more data is added, the model must generalize
  better, which may slightly increase training error.
\item
  \textbf{Validation Error Curve}: This indicates how well the model
  performs on unseen data. Initially, when training data is limited, the
  validation error tends to be high due to underfitting. As training
  data increases, the validation error generally decreases until it
  stabilizes.
\end{enumerate}

By analyzing the trends in these curves, one can diagnose different
learning behaviors: - \textbf{Underfitting} occurs when both training
and validation errors are high. This suggests that the model is too
simple and incapable of capturing underlying patterns in the data. -
\textbf{Overfitting} occurs when training error is very low while
validation error remains significantly higher. This indicates that the
model has learned noise from the training data instead of generalizable
patterns. - \textbf{Optimal Capacity} is achieved when both training and
validation errors converge to a stable point, indicating a model that
generalizes well to unseen data.

\subsubsection{Visualizing Learning Curves in
Python}\label{visualizing-learning-curves-in-python}

To better understand these concepts, let us generate learning curves
using Python. We will use a synthetic dataset and compare a simple
linear model with a more complex one.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{c+c1}{\PYZsh{} Generate synthetic data}
         \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{make\PYZus{}regression}\PY{p}{(}\PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{n\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{noise}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{c+c1}{\PYZsh{} Function to plot learning curves}
         \PY{k}{def} \PY{n+nf}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{title}\PY{p}{)}\PY{p}{:}
             \PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{test\PYZus{}scores} \PY{o}{=} \PY{n}{learning\PYZus{}curve}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{train\PYZus{}sizes}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{neg\PYZus{}mean\PYZus{}squared\PYZus{}error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{train\PYZus{}mean} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{test\PYZus{}mean} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{test\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{train\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{test\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation Error}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training Size}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Mean Squared Error}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{title}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{c+c1}{\PYZsh{} Plot learning curves for linear regression}
         \PY{n}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{LinearRegression}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Linear Regression Learning Curve}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot learning curves for decision tree}
         \PY{n}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{DecisionTreeRegressor}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree Learning Curve}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_21_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Interpretation of the
Results}\label{interpretation-of-the-results}

From the learning curves generated above, we observe distinct behaviors:

\begin{itemize}
\item
  The \textbf{linear regression model} generally exhibits high bias,
  meaning that both training and validation errors tend to remain high.
  This suggests underfitting and indicates that a more complex model
  might be necessary.
\item
  The \textbf{decision tree model} has a very low training error but a
  much higher validation error, suggesting overfitting. The model learns
  the training data too well but struggles to generalize to new data.
\end{itemize}

\subsubsection{Practical Implications}\label{practical-implications}

Understanding learning curves is essential when selecting a model for a
given task. If a model is underfitting, one might consider increasing
its complexity or using feature engineering to improve representation.
Conversely, if a model is overfitting, strategies such as
regularization, pruning (for decision trees), or increasing the amount
of training data can help improve generalization.

Additionally, learning curves provide guidance on whether collecting
more data would be beneficial. If both training and validation errors
continue to decrease as data increases, acquiring additional data could
enhance performance. However, if the validation error plateaus, adding
more data may not significantly improve results, and attention should be
shifted to model selection and optimization.

\subsubsection{Conclusion}\label{conclusion}

Learning curves offer a powerful tool for diagnosing and improving
machine learning models. By carefully analyzing how performance evolves
with increasing data, practitioners can make informed decisions about
model complexity, data collection strategies, and the need for
regularization techniques. As illustrated through the Python examples,
visualizing learning curves can provide clear evidence of model
behavior, aiding in the development of robust and generalizable machine
learning solutions.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{Image}\PY{p}{(}\PY{n}{filename}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{../05\PYZhy{}pictures/lesson\PYZhy{}4\PYZhy{}2\PYZus{}pic\PYZus{}3.png}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{l+m+mi}{800}\PY{p}{)} 
\end{Verbatim}

    \emph{Source: Raschka S. et al.~- Python Machine Learning - Chapter 6
(see Reference and Credits section)}

    \subsubsection{An Example with Real
Data}\label{an-example-with-real-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         
         \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https://archive.ics.uci.edu/ml/}\PY{l+s+s1}{\PYZsq{}}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{machine\PYZhy{}learning\PYZhy{}databases}\PY{l+s+s1}{\PYZsq{}}
         \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/breast\PYZhy{}cancer\PYZhy{}wisconsin/wdbc.data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
         \PY{n}{header}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{n}{df}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}40}]:}          0  1      2      3       4       5        6        7       8   \textbackslash{}
         0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   
         1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   
         2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   
         3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   
         4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   
         
                 9   {\ldots}     22     23      24      25      26      27      28      29  \textbackslash{}
         0  0.14710  {\ldots}  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   
         1  0.07017  {\ldots}  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   
         2  0.12790  {\ldots}  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   
         3  0.10520  {\ldots}  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   
         4  0.10430  {\ldots}  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   
         
                30       31  
         0  0.4601  0.11890  
         1  0.2750  0.08902  
         2  0.3613  0.08758  
         3  0.6638  0.17300  
         4  0.2364  0.07678  
         
         [5 rows x 32 columns]
\end{Verbatim}
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing} \PY{k+kn}{import} \PY{n}{LabelEncoder}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{values}
         \PY{n}{y} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{values}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{y}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
['M' 'M' 'M' 'M' 'M']

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{le} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
         \PY{n}{y}  \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{y}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
         \PY{n}{le}\PY{o}{.}\PY{n}{classes\PYZus{}}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
[1 1 1 1 1]

    \end{Verbatim}
\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}42}]:} array(['B', 'M'], dtype=object)
\end{Verbatim}
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.20}\PY{p}{,} \PY{n}{stratify}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{preprocessing}   \PY{k+kn}{import} \PY{n}{StandardScaler}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{linear\PYZus{}model}    \PY{k+kn}{import} \PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline}        \PY{k+kn}{import} \PY{n}{make\PYZus{}pipeline}
         
         \PY{n}{pipe\PYZus{}lr} \PY{o}{=} \PY{n}{make\PYZus{}pipeline}\PY{p}{(}\PY{n}{StandardScaler}\PY{p}{(}\PY{p}{)}\PY{p}{,}
             \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{penalty}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{l2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
             \PY{n}{solver}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lbfgs}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{n}{max\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{test\PYZus{}scores} \PY{o}{=}\PYZbs{}
             \PY{n}{learning\PYZus{}curve}\PY{p}{(}\PY{n}{estimator}\PY{o}{=}\PY{n}{pipe\PYZus{}lr}\PY{p}{,}
             \PY{n}{X}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{p}{,}
             \PY{n}{y}\PY{o}{=}\PY{n}{y\PYZus{}train}\PY{p}{,}
             \PY{n}{train\PYZus{}sizes}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}
             \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,}
             \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{,}
             \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{n}{train\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{train\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{test\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{test\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{test\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{test\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{train\PYZus{}mean}\PY{p}{,}
             \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{n}{markersize}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,}
             \PY{n}{train\PYZus{}mean} \PY{o}{+} \PY{n}{train\PYZus{}std}\PY{p}{,}
             \PY{n}{train\PYZus{}mean} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}std}\PY{p}{,}
             \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,} \PY{n}{test\PYZus{}mean}\PY{p}{,}
             \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
             \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{markersize}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,}
             \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Validation accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{train\PYZus{}sizes}\PY{p}{,}
             \PY{n}{test\PYZus{}mean} \PY{o}{+} \PY{n}{test\PYZus{}std}\PY{p}{,}
             \PY{n}{test\PYZus{}mean} \PY{o}{\PYZhy{}} \PY{n}{test\PYZus{}std}\PY{p}{,}
             \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.15}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{grid}\PY{p}{(}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Number of training examples}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lower right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{p}{[}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{l+m+mf}{1.03}\PY{p}{]}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Validation Curve}\label{validation-curve}

    As we have already said, selecting an optimal machine learning model
requires not only choosing the right algorithm but also fine-tuning its
hyperparameters. One of the most effective ways to assess the influence
of hyperparameters on model performance is through \textbf{validation
curves}. A validation curve is a diagnostic tool that helps in
understanding how a model behaves with varying hyperparameter values,
allowing practitioners to detect underfitting and overfitting.

\subsubsection{Theoretical Background}\label{theoretical-background}

A validation curve plots a model's performance against different values
of a specific hyperparameter. Typically, two curves are plotted: one for
training scores and another for validation scores. The key idea behind
validation curves is to analyze how the model's generalization
capability changes as the hyperparameter is modified.

When interpreting a validation curve, three possible patterns can
emerge: - \textbf{Underfitting}: If both the training and validation
scores are low and close to each other, the model is too simple and
fails to capture the complexity of the data. - \textbf{Overfitting}: If
the training score is high while the validation score is significantly
lower, the model is too complex and memorizes the training data rather
tha generalizing well. - \textbf{Optimal Generalization}: If both
training and validation scores are high and close to each other, the
model has achieved a good balance between bias and variance.

Understanding validation curves is crucial in model selection, as they
allow one to determine which hyperparameter values provide the best
trade-off between underfitting and overfitting.

\subsubsection{Implementing Validation Curves in
Python}\label{implementing-validation-curves-in-python}

To illustrate the concept, let us use the \texttt{validation\_curve}
function from \texttt{sklearn.model\_selection}. This function allows us
to compute training and validation scores for different hyperparameter
values. We will use the \textbf{Random Forest Regressor} to explore how
its performance changes with respect to the \texttt{max\_depth}
hyperparameter.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k+kn}{import} \PY{n}{tqdm}  \PY{c+c1}{\PYZsh{} Importing tqdm for progress bar}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{RandomForestRegressor}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{fetch\PYZus{}california\PYZus{}housing}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{,} \PY{n}{validation\PYZus{}curve}
         
         \PY{c+c1}{\PYZsh{} Load the California housing dataset}
         \PY{n}{housing} \PY{o}{=} \PY{n}{fetch\PYZus{}california\PYZus{}housing}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Extract features (X) and target variable (y)}
         \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{housing}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{housing}\PY{o}{.}\PY{n}{target}  
         
         \PY{c+c1}{\PYZsh{} Split dataset into training and test sets (80\PYZpc{} training, 20\PYZpc{} testing)}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Define the range of values for the hyperparameter (max\PYZus{}depth of the decision trees)}
         \PY{n}{param\PYZus{}range} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{21}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Testing max\PYZus{}depth}
         
         \PY{c+c1}{\PYZsh{} Initialize lists to store scores for progress bar visualization}
         \PY{n}{train\PYZus{}scores\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{val\PYZus{}scores\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Iterate through the parameter range with a progress bar}
         \PY{k}{for} \PY{n}{max\PYZus{}depth} \PY{o+ow}{in} \PY{n}{tqdm}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{desc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Computing validation curve}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Compute validation curve for the current hyperparameter value}
             \PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{val\PYZus{}scores} \PY{o}{=} \PY{n}{validation\PYZus{}curve}\PY{p}{(}
                 \PY{n}{RandomForestRegressor}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,}
                 \PY{n}{param\PYZus{}name}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{param\PYZus{}range}\PY{o}{=}\PY{p}{[}\PY{n}{max\PYZus{}depth}\PY{p}{]}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r2}\PY{l+s+s2}{\PYZdq{}}
             \PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Append mean scores to lists for plotting later}
             \PY{n}{train\PYZus{}scores\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{val\PYZus{}scores\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{val\PYZus{}scores}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Convert lists to NumPy arrays for easier manipulation}
         \PY{n}{train\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{train\PYZus{}scores\PYZus{}list}\PY{p}{)}
         \PY{n}{val\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{val\PYZus{}scores\PYZus{}list}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Compute standard deviation for confidence intervals}
         \PY{n}{train\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{train\PYZus{}scores\PYZus{}list}\PY{p}{)}
         \PY{n}{val\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{val\PYZus{}scores\PYZus{}list}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot validation curve}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{train\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{train\PYZus{}mean} \PY{o}{\PYZhy{}} \PY{n}{train\PYZus{}std}\PY{p}{,} \PY{n}{train\PYZus{}mean} \PY{o}{+} \PY{n}{train\PYZus{}std}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{val\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{val\PYZus{}mean} \PY{o}{\PYZhy{}} \PY{n}{val\PYZus{}std}\PY{p}{,} \PY{n}{val\PYZus{}mean} \PY{o}{+} \PY{n}{val\PYZus{}std}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Labels and title for the plot}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Max Depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Label for the x\PYZhy{}axis}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{R\PYZca{}2 Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Label for the y\PYZhy{}axis}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation Curve for Random Forest Regressor}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Plot title}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Show the legend}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Display the plot}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Computing validation curve: 100\%|██████████████████████████████████████████████████████| 20/20 [17:46<00:00, 53.34s/it]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_35_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Interpreting the Validation
Curve}\label{interpreting-the-validation-curve}

The plot generated from the above code provides insights into the effect
of \texttt{max\_depth} on model performance. If \texttt{max\_depth} is
too low, both training and validation scores remain low, indicating
underfitting. As \texttt{max\_depth} increases, the training score
improves significantly. However, if the validation score peaks and then
starts declining while the training score continues to rise, this
suggests that the model is beginning to overfit. The ideal value for
\texttt{max\_depth} is found where the validation score is maximized
before overfitting begins.

\subsubsection{Practical Applications}\label{practical-applications}

Validation curves are useful in several scenarios: -
\textbf{Hyperparameter tuning}: By visualizing how a specific
hyperparameter affects performance, one can make informed decisions
about its optimal value. - \textbf{Detecting overfitting and
underfitting}: If the gap between training and validation scores is
large, the model may be overfitting, requiring regularization
techniques. - \textbf{Improving generalization}: Understanding the
behavior of the model with different hyperparameters helps in selecting
configurations that generalize well to unseen data.

    \subsection{Grid Search}\label{grid-search}

    Fine-tuning process involves selecting the best hyperparameters, which
define how the learning algorithm behaves. Unlike model parameters,
which are learned from the data, hyperparameters are set manually before
training begins. A systematic approach to tuning these hyperparameters
is \textbf{grid search}, which evaluates a predefined set of
hyperparameter values to determine the optimal combination for a given
model.

\subsubsection{The Idea}\label{the-idea}

Grid search involves exhaustively searching through a \textbf{grid} of
possible hyperparameter values and selecting the combination that yields
the best performance based on a chosen evaluation metric. The process
typically involves: 1. Defining a set of hyperparameters and their
possible values. 2. Training the model using each combination of these
values. 3. Evaluating performance using cross-validation. 4. Selecting
the combination that maximizes the desired metric (e.g., accuracy,
R-squared, F1-score).

While grid search is computationally expensive, it provides a systematic
way to explore hyperparameter space. When the number of possible
hyperparameter combinations is very large, an alternative approach known
as \textbf{random search} can be used to sample a subset of values
instead of evaluating all possible configurations.

\subsubsection{Implementing Grid Search in
Python}\label{implementing-grid-search-in-python}

Scikit-learn provides a convenient implementation of grid search through
\texttt{GridSearchCV}. Below is an example of fine-tuning a
\textbf{Random Forest Regressor} using grid search.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{datasets} \PY{k+kn}{import} \PY{n}{fetch\PYZus{}california\PYZus{}housing}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{,} \PY{n}{GridSearchCV}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k+kn}{import} \PY{n}{RandomForestRegressor}
         \PY{k+kn}{from} \PY{n+nn}{tqdm} \PY{k+kn}{import} \PY{n}{tqdm}
         \PY{k+kn}{import} \PY{n+nn}{itertools}
         
         \PY{c+c1}{\PYZsh{} Load dataset}
         \PY{n}{housing} \PY{o}{=} \PY{n}{fetch\PYZus{}california\PYZus{}housing}\PY{p}{(}\PY{p}{)}
         \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{housing}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{housing}\PY{o}{.}\PY{n}{target}
         
         \PY{c+c1}{\PYZsh{} Split into training and test sets}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Define model}
         \PY{n}{rf} \PY{o}{=} \PY{n}{RandomForestRegressor}\PY{p}{(}\PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Define grid of hyperparameters}
         \PY{n}{param\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}estimators}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{]}\PY{p}{,}  \PY{c+c1}{\PYZsh{} Number of trees}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{]}\PY{p}{,}     \PY{c+c1}{\PYZsh{} Maximum depth of trees}
             \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{min\PYZus{}samples\PYZus{}split}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{]}  \PY{c+c1}{\PYZsh{} Minimum samples required to split a node}
         \PY{p}{\PYZcb{}}
         
         \PY{c+c1}{\PYZsh{} Calculate the total number of iterations}
         \PY{n}{total\PYZus{}combinations} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{itertools}\PY{o}{.}\PY{n}{product}\PY{p}{(}\PY{o}{*}\PY{n}{param\PYZus{}grid}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{5}  \PY{c+c1}{\PYZsh{} cv=5}
         
         \PY{c+c1}{\PYZsh{} Initialize tqdm progress bar}
         \PY{k}{with} \PY{n}{tqdm}\PY{p}{(}\PY{n}{total}\PY{o}{=}\PY{n}{total\PYZus{}combinations}\PY{p}{,} \PY{n}{desc}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Grid Search Progress}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{k}{as} \PY{n}{pbar}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{progress\PYZus{}callback}\PY{p}{(}\PY{o}{*}\PY{n}{args}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
                 \PY{n}{pbar}\PY{o}{.}\PY{n}{update}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Update progress bar after each fit iteration}
         
             \PY{c+c1}{\PYZsh{} Perform grid search with tqdm tracking}
             \PY{n}{grid\PYZus{}search} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{rf}\PY{p}{,} \PY{n}{param\PYZus{}grid}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{n\PYZus{}jobs}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{verbose}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
             \PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
             \PY{n}{pbar}\PY{o}{.}\PY{n}{close}\PY{p}{(}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Ensure progress bar is closed properly}
         
         \PY{c+c1}{\PYZsh{} Display best parameters and corresponding score}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best Hyperparameters:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}params\PYZus{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Best R\PYZca{}2 Score:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{grid\PYZus{}search}\PY{o}{.}\PY{n}{best\PYZus{}score\PYZus{}}\PY{p}{)}
\end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Grid Search Progress:   0\%|                                                                    | 0/135 [14:38<?, ?it/s]
    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Best Hyperparameters: \{'max\_depth': 20, 'min\_samples\_split': 2, 'n\_estimators': 200\}
Best R\^{}2 Score: 0.8050368931785936

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]


    \end{Verbatim}

    After running the grid search, the output reveals the optimal
combination of hyperparameters that achieved the highest
cross-validation score. The selected values should then be used to
retrain the model on the full training set before making final
predictions.

Although grid search is a powerful tool, it has some limitations:

\begin{itemize}
\item
  \textbf{Computational Cost}: As the number of hyperparameters
  increases, the number of combinations grows exponentially, making
  exhaustive search impractical for large grids.
\item
  \textbf{Curse of Dimensionality}: Some hyperparameters may be more
  influential than others, making it inefficient to search through all
  possible values blindly.
\item
  \textbf{Alternative Approaches}: Methods like \textbf{random search}
  and \textbf{Bayesian optimization} can offer more efficient
  alternatives for hyperparameter tuning, especially when the search
  space is large.
\end{itemize}

    \subsection{Reference and Credits}\label{reference-and-credits}

    \emph{Python Machine Learning 3rd Edition} by
\href{https://sebastianraschka.com}{Sebastian Raschka}, Packt Publishing
Ltd.~2019

Code Repository:
https://github.com/rasbt/python-machine-learning-book-3rd-edition

Code License:
\href{https://github.com/rasbt/python-machine-learning-book-3rd-edition/blob/master/LICENSE.txt}{MIT
License}


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
