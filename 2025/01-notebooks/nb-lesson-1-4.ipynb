{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/polyhedron-gdl/introduction-to-machine-learning-for-finance/blob/main/2022/1-notebooks/chapter-2-1.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: The Importance of Data Pre-Processing in Machine Learning\n",
    "\n",
    "Before applying any machine learning model, it is essential to establish a rigorous understanding of **data pre-processing**.  Poorly prepared data can lead to misleading conclusions, rendering even the most sophisticated algorithms ineffective.\n",
    "\n",
    "Data pre-processing introduces several key concepts that are **transversal to all of machine learning**. Among these, **handling missing values, feature scaling, encoding categorical variables, and detecting outliers** are crucial. These techniques ensure that the input data is structured, consistent, and suitable for training robust models. Without proper data preparation, models may struggle with convergence, exhibit bias, or fail to generalize to new data.\n",
    "\n",
    "To develop intuition for these ideas, we will use **simple datasets** as our primary tool. This choice allows us to focus on the core issues of **data cleaning, transformation, and feature engineering** without being overwhelmed by complex datasets or domain-specific knowledge. By using well-defined examples, we can systematically explore how different pre-processing techniques affect the model’s performance.\n",
    "\n",
    "In this lesson, we will cover the essential components of data pre-processing, including:\n",
    "\n",
    "- **Handling missing data: imputation and removal strategies**\n",
    "- **Feature scaling: normalization and standardization**\n",
    "- **Encoding categorical variables**\n",
    "- **Detecting and handling outliers**\n",
    "- **Feature Selection and Dimensionality Reduction**\n",
    "\n",
    "By mastering these principles early, we establish a solid foundation that will allow us to prepare datasets effectively for any machine learning application. With these concepts in place, we can confidently proceed to building and validating models, knowing that our data is well-structured and optimized for success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "Raw data rarely comes in the form and shape that is necessary for the optimal\n",
    "performance of a learning algorithm. On the other hand, the success of a machine learning algorithm highly depends on the quality of the data fed into the model. Real-world data is often dirty containing outliers, missing values, wrong data types, irrelevant features, or non-standardized data. The presence of any of these will prevent the machine learning model to properly learn. For this reason, transforming raw data into a useful format is an essential stage in the machine learning process. Therefore,\n",
    "it is absolutely critical to ensure that we examine and preprocess a dataset before\n",
    "we feed it to a learning algorithm. In this section, we will discuss the essential data\n",
    "preprocessing techniques that will help us to build good machine learning models.\n",
    "\n",
    "The topics that we will cover in this lesson are as follows:\n",
    "\n",
    "- Removing and imputing missing values from the dataset\n",
    "- Getting categorical data into shape for machine learning algorithms\n",
    "- Selecting relevant features for the model construction\n",
    "- Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philosophy of Use of Scikit-Learn\n",
    "\n",
    "Scikit-learn is one of the most widely used Python libraries for machine learning. Its design philosophy is centered on **simplicity, modularity, and consistency**, making it accessible to both beginners and advanced users.\n",
    "\n",
    "The **core principles** that guide the usage of scikit-learn are:\n",
    "1. **Unified API**: Every model (regression, classification, clustering, dimensionality reduction, etc.) follows the same pattern.\n",
    "2. **Minimal Configuration**: Most models work well with default parameters and can be fine-tuned later.\n",
    "3. **Consistency**: Whether you are dealing with a linear regression, decision tree, or neural network, the interaction with models remains the same.\n",
    "4. **Pipeline-Oriented**: Scikit-learn encourages a step-by-step workflow involving data preprocessing, model training, and prediction.\n",
    "\n",
    "### The Core Methods: `fit()`, `transform()`, `predict()`\n",
    "\n",
    "Scikit-learn is built around a **three-step workflow**: **fitting**, **transforming**, and **predicting**. Almost every estimator (a model or transformer) in scikit-learn follows these methods.\n",
    "\n",
    "**1. `fit()` – Learning from Data**\n",
    "\n",
    "- This method is used to **train** a model or a transformer on the given dataset.\n",
    "- It extracts relevant patterns, parameters, or statistics from the data.\n",
    "- Used in **both preprocessing transformers (e.g., scalers, PCA)** and **models (e.g., linear regression, decision trees)**.\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "or, for transformers:\n",
    "```python\n",
    "scaler.fit(X_train)\n",
    "```\n",
    "\n",
    "**Example: Linear Regression**\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = [[1], [2], [3], [4]]\n",
    "y_train = [2, 4, 6, 8]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Learns the relationship (y = 2x)\n",
    "```\n",
    "\n",
    "**Example: Standard Scaler**\n",
    "\n",
    "```python\n",
    "# The scaler methods in scikit-learn are preprocessing techniques used to normalize or \n",
    "# standardize numerical data before feeding it into a machine learning model.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = [[10], [20], [30], [40]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Computes mean and standard deviation\n",
    "```\n",
    "\n",
    "**2. `transform()` – Applying a Transformation**\n",
    "\n",
    "- Used **only by transformers** (not predictive models).\n",
    "- It applies a learned transformation to new data.\n",
    "- Example use cases:\n",
    "  - **Feature scaling (e.g., StandardScaler, MinMaxScaler)**\n",
    "  - **Dimensionality reduction (e.g., PCA)**\n",
    "  - **Encoding categorical variables (e.g., OneHotEncoder)**\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "```python\n",
    "X_transformed = transformer.transform(X_new)\n",
    "```\n",
    "\n",
    "**Example: Standard Scaler**\n",
    "\n",
    "```python\n",
    "X_test = [[25], [35]]\n",
    "\n",
    "X_scaled = scaler.transform(X_test)  # Applies scaling learned from fit()\n",
    "```\n",
    "\n",
    "> **Important:** `fit_transform(X)` is a shortcut for `fit(X)` followed by `transform(X)`.\n",
    "\n",
    "```python\n",
    "X_scaled = scaler.fit_transform(X_train)  # Often used in pipelines\n",
    "```\n",
    "\n",
    "**3. `predict()` – Making Predictions**\n",
    "\n",
    "- Used **only by predictive models** (not transformers).\n",
    "- Takes new input data (`X_test`) and outputs predictions (`y_pred`).\n",
    "- Works with both **classification (e.g., DecisionTreeClassifier, SVM)** and **regression (e.g., LinearRegression, RandomForestRegressor)**.\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "**Example: Predicting with Linear Regression**\n",
    "\n",
    "```python\n",
    "X_test = [[5], [6]]\n",
    "\n",
    "y_pred = model.predict(X_test)  # Output: [10, 12] (y = 2x)\n",
    "```\n",
    "\n",
    "### How These Methods Fit Together in a Typical Pipeline\n",
    "\n",
    "A typical **machine learning workflow** in scikit-learn follows these steps:\n",
    "\n",
    "1. **Preprocess the data** (fit and transform):\n",
    "   - Handle missing values, scale features, encode categorical variables.\n",
    "   - Example: `StandardScaler().fit_transform(X)`\n",
    "\n",
    "<p></p>\n",
    "\n",
    "2. **Train the model** (fit):\n",
    "   - Example: `model.fit(X_train, y_train)`\n",
    "\n",
    "<p></p>\n",
    "\n",
    "3. **Make predictions** (predict):\n",
    "   - Example: `y_pred = model.predict(X_test)`\n",
    "\n",
    "**Example: Full Pipeline**\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define pipeline: Scaling + Linear Regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # First, scale features\n",
    "    ('regressor', LinearRegression())  # Then, fit regression model\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "```\n",
    "\n",
    "**Key Takeaways**\n",
    "- `fit()`: **Learns** from the data (used by both transformers and models).\n",
    "- `transform()`: **Applies** learned transformations (only for transformers).\n",
    "- `predict()`: **Generates predictions** from trained models (only for predictive models).\n",
    "- **Scikit-learn enforces a uniform API**, making it easy to switch between models.\n",
    "- **Pipelines** streamline the workflow by combining preprocessing and modeling in a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "\n",
    "The real-world data often has a lot of missing values. The cause of missing values can be data corruption or failure to record data. The handling of missing data is very important during the preprocessing of the dataset as many machine learning algorithms do not support missing values.\n",
    "\n",
    "\n",
    "Let's create\n",
    "a simple example data frame from a comma-separated values (CSV) file to get\n",
    "a better grasp of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B     C     D\n",
       "0    1.0   2.0   3.0   4.0\n",
       "1    5.0   6.0   NaN   8.0\n",
       "2   10.0  11.0  12.0   NaN\n",
       "3   10.0  11.0  12.0  13.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#\n",
    "# The StringIO module is an in-memory file-like object. This object can be used as input or output \n",
    "# to the most function that would expect a standard file object. When the StringIO object is created \n",
    "# it is initialized by passing a string to the constructor. If no string is passed the StringIO will \n",
    "# start empty. In both cases, the initial cursor on the file starts at zero. NOTE: This module does \n",
    "# not exist in the latest version of Python so to work with this module we have to import it from \n",
    "# the io module.\n",
    "#\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = \\\n",
    "    '''\n",
    "    A,B,C,D\n",
    "    1.0,2.0,3.0,4.0\n",
    "    5.0,6.0,,8.0\n",
    "    10.0,11.0,12.0,\n",
    "    10.0,11.0,12.0,13.0\n",
    "    '''\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Rows with Missing Values \n",
    "\n",
    "One of the easiest ways to deal with missing data is simply to remove the\n",
    "corresponding features (columns) or training examples (rows) from the dataset\n",
    "entirely. Missing values can be handled by deleting the rows or columns having null values. If columns have more than half of the rows as null then the entire column can be dropped. The rows which are having one or more columns values as null can also be dropped.\n",
    "\n",
    "Remember that, in pandas, rows with missing values can easily be dropped via the **dropna** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B     C     D\n",
       "0    1.0   2.0   3.0   4.0\n",
       "3   10.0  11.0  12.0  13.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.dropna(axis=0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B\n",
       "0    1.0   2.0\n",
       "1    5.0   6.0\n",
       "2   10.0  11.0\n",
       "3   10.0  11.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna(axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the removal of missing data seems to be a convenient approach, it also\n",
    "comes with certain disadvantages; for example, we may end up removing too\n",
    "many samples, which will make a reliable analysis impossible. Or, if we remove too\n",
    "many feature columns, we will run the risk of losing valuable information that our\n",
    "classifier needs to discriminate between classes. In the next section, we will look\n",
    "at one of the most commonly used alternatives for dealing with missing values:\n",
    "interpolation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- A model trained with the removal of all missing values creates a robust model.\n",
    "\n",
    "**Cons**:\n",
    "- Loss of a lot of information.\n",
    "- Works poorly if the percentage of missing values is excessive in comparison to the complete dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values\n",
    "\n",
    "One of the most common interpolation\n",
    "techniques is called **imputation**, where we simply replace the missing value with\n",
    "the mean value of the entire feature column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**scikit-learn - SimpleImputer**\n",
    ">\n",
    ">A convenient way to achieve this is by\n",
    ">using the **SimpleImputer** class from scikit-learn. Scikit-learn, infact,  has built-in methods to perform these  preprocessing steps. For example, the `SimpleImputer()` fills in missing values using a method of your choice (see the code >below). The Scikit-learn documentation lists the full options for data preprocessing [here](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.        ,  3.        ,  4.        ],\n",
       "       [ 5.        ,  6.        ,  9.        ,  8.        ],\n",
       "       [10.        , 11.        , 12.        ,  8.33333333],\n",
       "       [10.        , 11.        , 12.        , 13.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "#\n",
    "# define the imputing method\n",
    "#\n",
    "imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, an even more convenient way to impute missing values is by using\n",
    "pandas' **fillna** method and providing an imputation method as an argument. For\n",
    "example, using pandas, we could achieve the same mean imputation directly in the\n",
    "DataFrame object via the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A     B     C          D\n",
       "0    1.0   2.0   3.0   4.000000\n",
       "1    5.0   6.0   9.0   8.000000\n",
       "2   10.0  11.0  12.0   8.333333\n",
       "3   10.0  11.0  12.0  13.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pros**:\n",
    "- Prevent data loss which results in deletion of rows or columns\n",
    "- Works well with a small dataset and is easy to implement.\n",
    "\n",
    "**Cons**:\n",
    "- Works only with numerical continuous variables.\n",
    "- Can cause data leakage\n",
    "- Do not factor the covariance between features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Delete Zero-Variance Predictors\n",
    "\n",
    "Zero-variance predictors refer to input features that contain a single value across the entire spectrum of observations. Accordingly, they do not add any value to the prediction algorithm since the target variable is not affected by the input value, making them redundant. Some ML algorithms might also run into unexpected errors or output wrong results.\n",
    "Pandas provides a function to count and list the number of unique values in each column of a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C     D     E     F     G     H\n",
       "0   1.0   2.0   3.0   4.0   5.0   6.0   7.0  42.0\n",
       "1   5.0   2.0   7.0   8.0   5.0   6.0  11.0  42.0\n",
       "2   9.0   6.0  11.0  12.0   9.0  10.0  15.0  42.0\n",
       "3  13.0   6.0  15.0  16.0   9.0  10.0  19.0  42.0\n",
       "4  17.0  10.0  19.0  20.0  13.0  14.0  23.0  42.0\n",
       "5  21.0  10.0  23.0  24.0  13.0  14.0  27.0  42.0\n",
       "6  25.0  14.0  27.0  28.0  17.0  18.0  31.0  42.0\n",
       "7  29.0  14.0  31.0  32.0  17.0  18.0  35.0  42.0\n",
       "8  33.0  18.0  35.0  36.0  21.0  22.0  39.0  42.0\n",
       "9  37.0  18.0  39.0  40.0  21.0  22.0  43.0  42.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = \\\n",
    "data_string = '''A,B,C,D,E,F,G,H\n",
    "1.0,2.0,3.0,4.0,5.0,6.0,7.0,42.0\n",
    "5.0,2.0,7.0,8.0,5.0,6.0,11.0,42.0\n",
    "9.0,6.0,11.0,12.0,9.0,10.0,15.0,42.0\n",
    "13.0,6.0,15.0,16.0,9.0,10.0,19.0,42.0\n",
    "17.0,10.0,19.0,20.0,13.0,14.0,23.0,42.0\n",
    "21.0,10.0,23.0,24.0,13.0,14.0,27.0,42.0\n",
    "25.0,14.0,27.0,28.0,17.0,18.0,31.0,42.0\n",
    "29.0,14.0,31.0,32.0,17.0,18.0,35.0,42.0\n",
    "33.0,18.0,35.0,36.0,21.0,22.0,39.0,42.0\n",
    "37.0,18.0,39.0,40.0,21.0,22.0,43.0,42.0'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "# Get number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(num_rows, num_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    10\n",
       "B     5\n",
       "C    10\n",
       "D    10\n",
       "E     5\n",
       "F     5\n",
       "G    10\n",
       "H     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will drop all columns that have a single value and update the df dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C     D     E     F     G\n",
      "0   1.0   2.0   3.0   4.0   5.0   6.0   7.0\n",
      "1   5.0   2.0   7.0   8.0   5.0   6.0  11.0\n",
      "2   9.0   6.0  11.0  12.0   9.0  10.0  15.0\n",
      "3  13.0   6.0  15.0  16.0   9.0  10.0  19.0\n",
      "4  17.0  10.0  19.0  20.0  13.0  14.0  23.0\n",
      "5  21.0  10.0  23.0  24.0  13.0  14.0  27.0\n",
      "6  25.0  14.0  27.0  28.0  17.0  18.0  31.0\n",
      "7  29.0  14.0  31.0  32.0  17.0  18.0  35.0\n",
      "8  33.0  18.0  35.0  36.0  21.0  22.0  39.0\n",
      "9  37.0  18.0  39.0  40.0  21.0  22.0  43.0\n",
      "      A     B     C     D     E     F     G     H\n",
      "0   1.0   2.0   3.0   4.0   5.0   6.0   7.0  42.0\n",
      "1   5.0   2.0   7.0   8.0   5.0   6.0  11.0  42.0\n",
      "2   9.0   6.0  11.0  12.0   9.0  10.0  15.0  42.0\n",
      "3  13.0   6.0  15.0  16.0   9.0  10.0  19.0  42.0\n",
      "4  17.0  10.0  19.0  20.0  13.0  14.0  23.0  42.0\n",
      "5  21.0  10.0  23.0  24.0  13.0  14.0  27.0  42.0\n",
      "6  25.0  14.0  27.0  28.0  17.0  18.0  31.0  42.0\n",
      "7  29.0  14.0  31.0  32.0  17.0  18.0  35.0  42.0\n",
      "8  33.0  18.0  35.0  36.0  21.0  22.0  39.0  42.0\n",
      "9  37.0  18.0  39.0  40.0  21.0  22.0  43.0  42.0\n"
     ]
    }
   ],
   "source": [
    "df2 = df.drop(columns = df.columns[df.nunique() == 1],inplace = False)\n",
    "print(df2)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C     D     E     F     G\n",
       "0   1.0   2.0   3.0   4.0   5.0   6.0   7.0\n",
       "1   5.0   2.0   7.0   8.0   5.0   6.0  11.0\n",
       "2   9.0   6.0  11.0  12.0   9.0  10.0  15.0\n",
       "3  13.0   6.0  15.0  16.0   9.0  10.0  19.0\n",
       "4  17.0  10.0  19.0  20.0  13.0  14.0  23.0\n",
       "5  21.0  10.0  23.0  24.0  13.0  14.0  27.0\n",
       "6  25.0  14.0  27.0  28.0  17.0  18.0  31.0\n",
       "7  29.0  14.0  31.0  32.0  17.0  18.0  35.0\n",
       "8  33.0  18.0  35.0  36.0  21.0  22.0  39.0\n",
       "9  37.0  18.0  39.0  40.0  21.0  22.0  43.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = df.columns[df.nunique() == 1], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **pandas remind**: Here’s a concise reminder of the key **pandas** syntax properties used in the given instruction:\n",
    ">\n",
    ">1. **`df.nunique()`**  \n",
    ">   - Returns the number of unique values for each column in the DataFrame.\n",
    ">\n",
    ">2. **`df.columns[...]`**  \n",
    ">   - Retrieves the column labels of the DataFrame.\n",
    ">   - `df.columns[df.nunique() == 1]` selects columns where all values are the same (i.e., with only one unique value).\n",
    ">\n",
    ">3. **`df.drop(columns=...)`**  \n",
    ">   - Drops the specified columns from the DataFrame.\n",
    ">   - `inplace=False` ensures that the original DataFrame remains unchanged, returning a new modified DataFrame (`df2` in this >case). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data is a form of data that takes on values within a finite set of discrete classes. It is difficult to count or measure categorical data using numbers and therefore they are divided into categories: **ordinal** and **nominal** features. \n",
    "\n",
    "**Ordinal** features can be understood as categorical\n",
    "values that *can be sorted or ordered*. For example, t-shirt size would be an ordinal\n",
    "feature, because we can define an order: XL > L > M. \n",
    "\n",
    "In contrast, **nominal** features\n",
    "don't imply any order and, to continue with the previous example, we could think\n",
    "of t-shirt color as a nominal feature since it typically doesn't make sense to say that,\n",
    "for example, red is larger than blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explore different techniques for handling such categorical data, let's create a new DataFrame to illustrate the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating  income  age employment_status  loan_amount default_history\n",
       "0     CC  172136   49        Unemployed       385030              No\n",
       "1     CC  128712   46        Unemployed       294572              No\n",
       "2      D  123129   48          Employed        73211              No\n",
       "3     BB  153940   21          Employed       217991              No\n",
       "4     BB   34905   22        Unemployed        44238              No\n",
       "5     BB   22174   59     Self-Employed       130365              No\n",
       "6      C   57352   62          Employed        26513              No\n",
       "7      B  121403   40          Employed         5823             Yes\n",
       "8     CC  147412   41     Self-Employed        29195              No\n",
       "9      C   58682   30        Unemployed       394905             Yes"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define possible S&P ratings\n",
    "ratings = [\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"CC\", \"C\", \"D\"]\n",
    "\n",
    "num_samples = 10\n",
    "\n",
    "# Generate an updated synthetic dataset\n",
    "df = pd.DataFrame({\n",
    "    \"rating\": np.random.choice(ratings, num_samples),                 # Random S&P rating assignment\n",
    "    \"income\": np.random.randint(20000, 200000, num_samples),          # Income in dollars\n",
    "    \"age\": np.random.randint(18, 75, num_samples),                    # Age of the individual\n",
    "    \"employment_status\": np.random.choice([\"Employed\", \"Unemployed\", \"Self-Employed\"], num_samples),\n",
    "    \"loan_amount\": np.random.randint(5000, 500000, num_samples),      # Loan amount in dollars\n",
    "    \"default_history\": np.random.choice([\"Yes\", \"No\"], num_samples, p=[0.2, 0.8])  # 20% default history\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **REMIND - FEATURES AND LABELS**\n",
    "> ***\n",
    "> Remember that in machine learning, you have **features** and **labels**. *The features are the **descriptive** attributes*, and *the \n",
    "> label is what you're attempting to predict or forecast*. In this simple example, **rating**, **income**, **age**, **employment_status** and **loan_amount** are **features** while \n",
    "> **default_history** is the field that contains the **label** of the corresponding record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that the learning algorithm interprets the ordinal features correctly,\n",
    "we need to convert the categorical string values into integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "      <th>rating_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>No</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating  income  age employment_status  loan_amount default_history  \\\n",
       "0     CC  172136   49        Unemployed       385030              No   \n",
       "1     CC  128712   46        Unemployed       294572              No   \n",
       "2      D  123129   48          Employed        73211              No   \n",
       "3     BB  153940   21          Employed       217991              No   \n",
       "4     BB   34905   22        Unemployed        44238              No   \n",
       "5     BB   22174   59     Self-Employed       130365              No   \n",
       "6      C   57352   62          Employed        26513              No   \n",
       "7      B  121403   40          Employed         5823             Yes   \n",
       "8     CC  147412   41     Self-Employed        29195              No   \n",
       "9      C   58682   30        Unemployed       394905             Yes   \n",
       "\n",
       "   rating_encoded  \n",
       "0             7.0  \n",
       "1             7.0  \n",
       "2             9.0  \n",
       "3             4.0  \n",
       "4             4.0  \n",
       "5             4.0  \n",
       "6             8.0  \n",
       "7             5.0  \n",
       "8             7.0  \n",
       "9             8.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ratings = [[\"AAA\", \"AA\", \"A\", \"BBB\", \"BB\", \"B\", \"CCC\", \"CC\", \"C\", \"D\"]]\n",
    "\n",
    "le = OrdinalEncoder(categories=ratings)\n",
    "df[\"rating_encoded\"] = le.fit_transform(df[[\"rating\"]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "      <th>rating_encoded</th>\n",
       "      <th>rating_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BB</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BB</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>No</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating  income  age employment_status  loan_amount default_history  \\\n",
       "0     CC  172136   49        Unemployed       385030              No   \n",
       "1     CC  128712   46        Unemployed       294572              No   \n",
       "2      D  123129   48          Employed        73211              No   \n",
       "3     BB  153940   21          Employed       217991              No   \n",
       "4     BB   34905   22        Unemployed        44238              No   \n",
       "5     BB   22174   59     Self-Employed       130365              No   \n",
       "6      C   57352   62          Employed        26513              No   \n",
       "7      B  121403   40          Employed         5823             Yes   \n",
       "8     CC  147412   41     Self-Employed        29195              No   \n",
       "9      C   58682   30        Unemployed       394905             Yes   \n",
       "\n",
       "   rating_encoded  rating_numeric  \n",
       "0             7.0               7  \n",
       "1             7.0               7  \n",
       "2             9.0               9  \n",
       "3             4.0               4  \n",
       "4             4.0               4  \n",
       "5             4.0               4  \n",
       "6             8.0               8  \n",
       "7             5.0               5  \n",
       "8             7.0               7  \n",
       "9             8.0               8  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_map = {\n",
    "    \"AAA\": 0, \"AA\": 1, \"A\": 2, \"BBB\": 3, \"BB\": 4, \n",
    "    \"B\": 5, \"CCC\": 6, \"CC\": 7, \"C\": 8, \"D\": 9\n",
    "}\n",
    "df[\"rating_numeric\"] = df[\"rating\"].map(rating_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Preprocessing : sklearn.preprocessing**\n",
    "> \n",
    "> Among some commonly used preprocessing tasks come `OneHotEncoder`, `StandardScaler`, `MinMaxScaler`, etc. These are respectively for encoding of the categorical features into a one-hot numeric array, standardization of the features and scaling each feature to a given range. Many other preprocessing methods are built-in this module.\n",
    "We can import this module as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  income  age employment_status  loan_amount default_history\n",
       "0       7  172136   49        Unemployed       385030              No\n",
       "1       7  128712   46        Unemployed       294572              No\n",
       "2       9  123129   48          Employed        73211              No\n",
       "3       4  153940   21          Employed       217991              No\n",
       "4       4   34905   22        Unemployed        44238              No\n",
       "5       4   22174   59     Self-Employed       130365              No\n",
       "6       8   57352   62          Employed        26513              No\n",
       "7       5  121403   40          Employed         5823             Yes\n",
       "8       7  147412   41     Self-Employed        29195              No\n",
       "9       8   58682   30        Unemployed       394905             Yes"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop(columns=[\"rating\", \"rating_encoded\"], inplace=False)\n",
    "df2.rename(columns={\"rating_numeric\":\"rating\"}, inplace=True)\n",
    "\n",
    "cols = [\"rating\"] + [col for col in df2.columns if col != \"rating\"]\n",
    "df2 = df2[cols]\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Class Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning libraries require that class labels are encoded as integer\n",
    "values. Although most estimators for classification in scikit-learn convert class\n",
    "labels to integers internally, it is considered good practice to provide class labels as\n",
    "integer arrays to avoid technical glitches. To encode the class labels, we can use an\n",
    "approach similar to the mapping of ordinal features discussed previously. We need\n",
    "to remember that class labels are not ordinal, and it doesn't matter which integer\n",
    "number we assign to a particular string label. Thus, we can simply enumerate\n",
    "the class labels, starting at 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'background-color:skyblue'>\n",
    "    <strong>Python Pills</strong>\n",
    "    <p>\n",
    "    enumerate() method in Python\n",
    "    </p>    \n",
    "    <p>\n",
    "    Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method.\n",
    "    </p>        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': 0, 'Yes': 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class_mapping = {label: idx for idx, label in enumerate(np.unique(df2['default_history']))}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the mapping dictionary to transform the class labels into integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  income  age employment_status  loan_amount  default_history\n",
       "0       7  172136   49        Unemployed       385030                0\n",
       "1       7  128712   46        Unemployed       294572                0\n",
       "2       9  123129   48          Employed        73211                0\n",
       "3       4  153940   21          Employed       217991                0\n",
       "4       4   34905   22        Unemployed        44238                0\n",
       "5       4   22174   59     Self-Employed       130365                0\n",
       "6       8   57352   62          Employed        26513                0\n",
       "7       5  121403   40          Employed         5823                1\n",
       "8       7  147412   41     Self-Employed        29195                0\n",
       "9       8   58682   30        Unemployed       394905                1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['default_history'] = df['default_history'].map(class_mapping)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reverse the key-value pairs in the mapping dictionary as follows to map the\n",
    "converted class labels back to the original string representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>172136</td>\n",
       "      <td>49</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>385030</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>128712</td>\n",
       "      <td>46</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>294572</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>123129</td>\n",
       "      <td>48</td>\n",
       "      <td>Employed</td>\n",
       "      <td>73211</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>153940</td>\n",
       "      <td>21</td>\n",
       "      <td>Employed</td>\n",
       "      <td>217991</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34905</td>\n",
       "      <td>22</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>44238</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>22174</td>\n",
       "      <td>59</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>130365</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>57352</td>\n",
       "      <td>62</td>\n",
       "      <td>Employed</td>\n",
       "      <td>26513</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>121403</td>\n",
       "      <td>40</td>\n",
       "      <td>Employed</td>\n",
       "      <td>5823</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>147412</td>\n",
       "      <td>41</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>29195</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>58682</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>394905</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  income  age employment_status  loan_amount default_history\n",
       "0       7  172136   49        Unemployed       385030              No\n",
       "1       7  128712   46        Unemployed       294572              No\n",
       "2       9  123129   48          Employed        73211              No\n",
       "3       4  153940   21          Employed       217991              No\n",
       "4       4   34905   22        Unemployed        44238              No\n",
       "5       4   22174   59     Self-Employed       130365              No\n",
       "6       8   57352   62          Employed        26513              No\n",
       "7       5  121403   40          Employed         5823             Yes\n",
       "8       7  147412   41     Self-Employed        29195              No\n",
       "9       8   58682   30        Unemployed       394905             Yes"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "df2['default_history'] = df2['default_history'].map(inv_class_mapping)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, there is a convenient LabelEncoder class directly implemented in\n",
    "scikit-learn to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df2['default_history'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding vs Label Encoding: Key Differences\n",
    "\n",
    "Both **Ordinal Encoding** and **Label Encoding** transform categorical data into numerical values, but they serve different purposes and have distinct behaviors. \n",
    "\n",
    "**1. Ordinal Encoding (`OrdinalEncoder`)**\n",
    "\n",
    "**Concept**:  \n",
    "\n",
    "- Each unique category is **mapped to an integer** based on a specific order.\n",
    "- **It preserves the order** of the categories.\n",
    "\n",
    "**Example: Credit Ratings**\n",
    "| Rating | Ordinal Encoding |\n",
    "|---------|----------------|\n",
    "| CCC     | 0              |\n",
    "| B       | 1              |\n",
    "| BB      | 2              |\n",
    "| BBB     | 3              |\n",
    "| A       | 4              |\n",
    "| AA      | 5              |\n",
    "| AAA     | 6              |\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'rating': ['AAA', 'BB', 'A', 'CCC', 'AA']})\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[['CCC', 'B', 'BB', 'BBB', 'A', 'AA', 'AAA']])\n",
    "data['rating_encoded'] = encoder.fit_transform(data[['rating']])\n",
    "\n",
    "print(data)\n",
    "```\n",
    "\n",
    "**When to Use Ordinal Encoding?**\n",
    "\n",
    "✔ When the categorical variable has an **intrinsic order** (e.g., credit rating, education level, survey ratings). \n",
    "\n",
    "❌ Not ideal for unordered categorical variables like `color`, `city`, or `car brands`.\n",
    "\n",
    "**2. Label Encoding (`LabelEncoder`)**\n",
    "\n",
    "**Concept**:\n",
    "\n",
    "- Assigns **a unique integer** to each category **without considering order**.\n",
    "- The numbers **do not represent any ranking**—they are just arbitrary labels.\n",
    "\n",
    "**Example: Car Brands**\n",
    "\n",
    "| Car Brand | Label Encoding |\n",
    "|-----------|---------------|\n",
    "| Toyota    | 0             |\n",
    "| Ford      | 1             |\n",
    "| BMW       | 2             |\n",
    "| Tesla     | 3             |\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.DataFrame({'car_brand': ['Toyota', 'Ford', 'BMW', 'Tesla', 'Ford']})\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['brand_encoded'] = encoder.fit_transform(data['car_brand'])\n",
    "\n",
    "print(data)\n",
    "```\n",
    "\n",
    "**When to Use Label Encoding?**\n",
    "\n",
    "✔ When the categorical variable is **nominal** (i.e., no natural order).  \n",
    "\n",
    "❌ Not suitable for ordinal variables (e.g., credit ratings), as it might **mislead models into thinking there's an order when there isn’t**.\n",
    "\n",
    "**Key Differences**\n",
    "\n",
    "| Feature          | Ordinal Encoding | Label Encoding |\n",
    "|-----------------|----------------|---------------|\n",
    "| **Preserves Order?** | ✅ Yes | ❌ No |\n",
    "| **Use Case** | Ordered categories (e.g., credit rating, survey responses) | Unordered categories (e.g., city names, brands) |\n",
    "| **Assigns Numeric Values?** | ✅ Yes | ✅ Yes |\n",
    "| **Numbers Represent Ranking?** | ✅ Yes | ❌ No |\n",
    "| **Risk of Misinterpretation?** | 🚨 If order is incorrect | 🚨 If used on ordinal data |\n",
    "| **Scikit-Learn Class** | `OrdinalEncoder` | `LabelEncoder` |\n",
    "\n",
    "\n",
    "**When to Avoid These Encodings?**\n",
    "\n",
    "If the categorical variable is **nominal** (no order) and has **many unique values**, both methods can cause issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is no a natural order we have to resort to a different approach that is to use the technique called **one-hot encoding**.  The idea behind this approach is to create a new dummy feature for each\n",
    "unique value in the nominal feature column. Here, we would convert the `employment_status`\n",
    "feature into three new features: *employed*, *self_employed*, and *unemployed*. Binary values can then be used\n",
    "to indicate the particular employment status of an example; for example, an employed customer can be\n",
    "encoded as *employed=1, self_employed=0, unemployed=0*. To perform this transformation, we can use the\n",
    "`OneHotEncoder` that is implemented in `scikit-learn`'s preprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = df2[['employment_status']].values\n",
    "color_ohe = OneHotEncoder()\n",
    "color_ohe.fit_transform(X[:, 0].reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to create those dummy features via one-hot encoding\n",
    "is to use the get_dummies method implemented in pandas. Applied to a DataFrame,\n",
    "the get_dummies method will only convert string columns and leave all other\n",
    "columns unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment_status_Employed</th>\n",
       "      <th>employment_status_Self-Employed</th>\n",
       "      <th>employment_status_Unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employment_status_Employed  employment_status_Self-Employed  \\\n",
       "0                       False                            False   \n",
       "1                       False                            False   \n",
       "2                        True                            False   \n",
       "3                        True                            False   \n",
       "4                       False                            False   \n",
       "5                       False                             True   \n",
       "6                        True                            False   \n",
       "7                        True                            False   \n",
       "8                       False                             True   \n",
       "9                       False                            False   \n",
       "\n",
       "   employment_status_Unemployed  \n",
       "0                          True  \n",
       "1                          True  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                          True  \n",
       "5                         False  \n",
       "6                         False  \n",
       "7                         False  \n",
       "8                         False  \n",
       "9                          True  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df2[['employment_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning algorithms require that the selected features are on\n",
    "the same scale for optimal performance, this process is called \"Feature Normalization\" and is the subject of this paragraph.\n",
    "\n",
    "Data Normalization is a common practice in machine learning which consists of transforming numeric columns to a common scale. In machine learning, some feature values differ from others multiple times. The features with higher values will dominate the leaning process. However, it does not mean those variables are more important to predict the outcome of the model. Data normalization transforms multiscaled data to the same scale. After normalization, all variables have a similar influence on the model, improving the stability and performance of the learning algorithm.\n",
    "\n",
    "There are multiple normalization techniques in statistics. In this notebook, we will cover the most important ones:\n",
    "\n",
    "- The maximum absolute scaling\n",
    "- The min-max feature scaling\n",
    "- The z-score method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum absolute scaling\n",
    "\n",
    "The maximum absolute scaling rescales each feature between -1 and 1 by dividing every observation by its maximum absolute value.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}}{\\max \\vert x_{old} \\vert}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The min-max feature scaling\n",
    "\n",
    "The min-max approach (often called normalization) rescales the feature to a fixed range of [0,1] by subtracting the minimum value of the feature and then dividing by the range:\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old}-x_{min}}{x_{max}-x_{min}}\n",
    "$$\n",
    "\n",
    "The min-max scaling procedure is implemented in scikit-learn and can be used as\n",
    "follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here we have to load the file 'salary_vs_age_1.csv'\n",
    "#\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    path = ''\n",
    "else:\n",
    "    path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Salary\n",
      "0   25  135000\n",
      "1   27  105000\n",
      "2   30  105000\n",
      "3   35  220000\n",
      "4   40  300000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Age</th>\n",
       "      <th>Age2</th>\n",
       "      <th>Age3</th>\n",
       "      <th>Age4</th>\n",
       "      <th>Age5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>25</td>\n",
       "      <td>625</td>\n",
       "      <td>15625</td>\n",
       "      <td>390625</td>\n",
       "      <td>9765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>27</td>\n",
       "      <td>729</td>\n",
       "      <td>19683</td>\n",
       "      <td>531441</td>\n",
       "      <td>14348907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>27000</td>\n",
       "      <td>810000</td>\n",
       "      <td>24300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1225</td>\n",
       "      <td>42875</td>\n",
       "      <td>1500625</td>\n",
       "      <td>52521875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1600</td>\n",
       "      <td>64000</td>\n",
       "      <td>2560000</td>\n",
       "      <td>102400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>270.0</td>\n",
       "      <td>45</td>\n",
       "      <td>2025</td>\n",
       "      <td>91125</td>\n",
       "      <td>4100625</td>\n",
       "      <td>184528125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265.0</td>\n",
       "      <td>50</td>\n",
       "      <td>2500</td>\n",
       "      <td>125000</td>\n",
       "      <td>6250000</td>\n",
       "      <td>312500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260.0</td>\n",
       "      <td>55</td>\n",
       "      <td>3025</td>\n",
       "      <td>166375</td>\n",
       "      <td>9150625</td>\n",
       "      <td>503284375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3600</td>\n",
       "      <td>216000</td>\n",
       "      <td>12960000</td>\n",
       "      <td>777600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>265.0</td>\n",
       "      <td>65</td>\n",
       "      <td>4225</td>\n",
       "      <td>274625</td>\n",
       "      <td>17850625</td>\n",
       "      <td>1160290625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary  Age  Age2    Age3      Age4        Age5\n",
       "0   135.0   25   625   15625    390625     9765625\n",
       "1   105.0   27   729   19683    531441    14348907\n",
       "2   105.0   30   900   27000    810000    24300000\n",
       "3   220.0   35  1225   42875   1500625    52521875\n",
       "4   300.0   40  1600   64000   2560000   102400000\n",
       "5   270.0   45  2025   91125   4100625   184528125\n",
       "6   265.0   50  2500  125000   6250000   312500000\n",
       "7   260.0   55  3025  166375   9150625   503284375\n",
       "8   240.0   60  3600  216000  12960000   777600000\n",
       "9   265.0   65  4225  274625  17850625  1160290625"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Pandas libraries with alias 'pd' \n",
    "import pandas as pd \n",
    "# Read data from file 'salary_vs_age_1.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "# Control delimiters, with read_table \n",
    "df1 = pd.read_table(path + \"salary_vs_age_1.csv\", sep=\";\") \n",
    "# Preview the first 5 lines of the loaded data \n",
    "print(df1.head())\n",
    "\n",
    "columns_titles = [\"Salary\",\"Age\"]\n",
    "df2=df1.reindex(columns=columns_titles)\n",
    "df2\n",
    "\n",
    "df2['Salary'] = df2['Salary']/1000 \n",
    "df2['Age2']=df2['Age']**2\n",
    "df2['Age3']=df2['Age']**3\n",
    "df2['Age4']=df2['Age']**4\n",
    "df2['Age5']=df2['Age']**5\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.028889</td>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.003984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.043919</td>\n",
       "      <td>0.024019</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.105212</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>0.037162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.186776</td>\n",
       "      <td>0.124248</td>\n",
       "      <td>0.080515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.291506</td>\n",
       "      <td>0.212486</td>\n",
       "      <td>0.151898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.422297</td>\n",
       "      <td>0.335588</td>\n",
       "      <td>0.263127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>0.501718</td>\n",
       "      <td>0.428951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.773649</td>\n",
       "      <td>0.719895</td>\n",
       "      <td>0.667377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1         2         3         4         5\n",
       "0  0.153846  0.000  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.000000  0.050  0.028889  0.015668  0.008065  0.003984\n",
       "2  0.000000  0.125  0.076389  0.043919  0.024019  0.012633\n",
       "3  0.589744  0.250  0.166667  0.105212  0.063574  0.037162\n",
       "4  1.000000  0.375  0.270833  0.186776  0.124248  0.080515\n",
       "5  0.846154  0.500  0.388889  0.291506  0.212486  0.151898\n",
       "6  0.820513  0.625  0.520833  0.422297  0.335588  0.263127\n",
       "7  0.794872  0.750  0.666667  0.582046  0.501718  0.428951\n",
       "8  0.692308  0.875  0.826389  0.773649  0.719895  0.667377\n",
       "9  0.820513  1.000  1.000000  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "df3 = pd.DataFrame(mms.fit_transform(df2))\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score\n",
    "\n",
    "The **z-score** method (often called **standardization**) transforms the data into a distribution with a mean of 0 and a standard deviation of 1. Each standardized value is computed by subtracting the mean of the corresponding feature and then dividing by the standard deviation.\n",
    "\n",
    "$$\n",
    "x_{new} = \\frac{x_{old} - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Unlike min-max scaling, the z-score does not rescale the feature to a fixed range. The z-score typically ranges from -3.00 to 3.00 (more than 99% of the data) if the input is normally distributed.\n",
    "\n",
    "It is important to bear in mind that z-scores are not necessarily normally distributed. They just scale the data and follow the same distribution as the original input. This transformed distribution has a mean of 0 and a standard deviation of 1 and is going to be the standard normal distribution only if the input feature follows a normal distribution.\n",
    "\n",
    "Standardization can easily be achieved by using the built-in NumPy methods mean\n",
    "and std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.39443338 -1.19522861 -1.19522861 -0.19920477  0.          0.\n",
      "  0.39840954  0.5976143   1.19522861  1.79284291]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([6, 7, 7, 12, 13, 13, 15, 16, 19, 22])\n",
    "\n",
    "X_std = np.copy(X)\n",
    "X_std = (X - X.mean()) / X.std()\n",
    "\n",
    "print(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply using the specific function of the stats module of scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.39443338, -1.19522861, -1.19522861, -0.19920477,  0.        ,\n",
       "        0.        ,  0.39840954,  0.5976143 ,  1.19522861,  1.79284291])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.zscore(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization is very useful with gradient descent learning. In this case\n",
    "the optimizer has to go through fewer steps to find a good or optimal solution (the\n",
    "global cost minimum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the MinMaxScaler class, scikit-learn also implements a class for\n",
    "standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.170242</td>\n",
       "      <td>-1.359724</td>\n",
       "      <td>-1.189131</td>\n",
       "      <td>-1.041783</td>\n",
       "      <td>-0.920815</td>\n",
       "      <td>-0.824435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.601005</td>\n",
       "      <td>-1.210304</td>\n",
       "      <td>-1.102065</td>\n",
       "      <td>-0.994071</td>\n",
       "      <td>-0.895974</td>\n",
       "      <td>-0.812022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.601005</td>\n",
       "      <td>-0.986174</td>\n",
       "      <td>-0.958907</td>\n",
       "      <td>-0.908042</td>\n",
       "      <td>-0.846835</td>\n",
       "      <td>-0.785069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050256</td>\n",
       "      <td>-0.612623</td>\n",
       "      <td>-0.686823</td>\n",
       "      <td>-0.721391</td>\n",
       "      <td>-0.725003</td>\n",
       "      <td>-0.708630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.198959</td>\n",
       "      <td>-0.239072</td>\n",
       "      <td>-0.372880</td>\n",
       "      <td>-0.473014</td>\n",
       "      <td>-0.538122</td>\n",
       "      <td>-0.573535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.768195</td>\n",
       "      <td>0.134478</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>-0.154092</td>\n",
       "      <td>-0.266345</td>\n",
       "      <td>-0.351091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.696401</td>\n",
       "      <td>0.508029</td>\n",
       "      <td>0.380582</td>\n",
       "      <td>0.244194</td>\n",
       "      <td>0.112820</td>\n",
       "      <td>-0.004480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.624608</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.820102</td>\n",
       "      <td>0.730661</td>\n",
       "      <td>0.624511</td>\n",
       "      <td>0.512260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.337432</td>\n",
       "      <td>1.255130</td>\n",
       "      <td>1.301481</td>\n",
       "      <td>1.314127</td>\n",
       "      <td>1.296512</td>\n",
       "      <td>1.255243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.696401</td>\n",
       "      <td>1.628681</td>\n",
       "      <td>1.824719</td>\n",
       "      <td>2.003411</td>\n",
       "      <td>2.159252</td>\n",
       "      <td>2.291760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "0 -1.170242 -1.359724 -1.189131 -1.041783 -0.920815 -0.824435\n",
       "1 -1.601005 -1.210304 -1.102065 -0.994071 -0.895974 -0.812022\n",
       "2 -1.601005 -0.986174 -0.958907 -0.908042 -0.846835 -0.785069\n",
       "3  0.050256 -0.612623 -0.686823 -0.721391 -0.725003 -0.708630\n",
       "4  1.198959 -0.239072 -0.372880 -0.473014 -0.538122 -0.573535\n",
       "5  0.768195  0.134478 -0.017078 -0.154092 -0.266345 -0.351091\n",
       "6  0.696401  0.508029  0.380582  0.244194  0.112820 -0.004480\n",
       "7  0.624608  0.881579  0.820102  0.730661  0.624511  0.512260\n",
       "8  0.337432  1.255130  1.301481  1.314127  1.296512  1.255243\n",
       "9  0.696401  1.628681  1.824719  2.003411  2.159252  2.291760"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "df4 = pd.DataFrame(stdsc.fit_transform(df2))\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chocolate Bar Ratings\n",
    "\n",
    "**Context**\n",
    "\n",
    "Chocolate is one of the most popular candies in the world. Each year, residents of the United States collectively eat more than 2.8 billions pounds. However, not all chocolate bars are created equal! This dataset contains expert ratings of over 1,700 individual chocolate bars, along with information on their regional origin, percentage of cocoa, the variety of chocolate bean used and where the beans were grown.\n",
    "\n",
    "**Flavors of Cacao Rating System**:\n",
    "\n",
    "5= Elite (Transcending beyond the ordinary limits)\n",
    "4= Premium (Superior flavor development, character and style)\n",
    "3= Satisfactory(3.0) to praiseworthy(3.75) (well made with special qualities)\n",
    "2= Disappointing (Passable but contains at least one significant flaw)\n",
    "1= Unpleasant (mostly unpalatable)\n",
    "\n",
    "**Link**\n",
    "\n",
    "https://www.kaggle.com/rtatman/chocolate-bar-ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** \n",
    "\n",
    "Download the `csv` file from the kaggle web page above and perform a simple visualization\n",
    "\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "First of all you need to import pandas library, then define a variable path (the folder in which you saved the csv file) and finally load the file using the method read_csv of pandas. Use the method head() to have a look to the first lines:\n",
    "    \n",
    "```python\n",
    "import pandas as pd\n",
    "    \n",
    "path = './data'\n",
    "df = pd.read_csv(path + \"/flavors_of_cacao.csv\")\n",
    "df.head()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put here your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** \n",
    "\n",
    "Change columns names into:\n",
    "\n",
    "- \"Company\"\n",
    "- \"Spec_Bean_Origin_or_Bar_Name\"\n",
    "- \"Review_Date\"\n",
    "- \"Cocoa_Percent\"\n",
    "- \"Company_Location\"\n",
    "- \"Bean_Type\"\"Broad_Bean_Origin\"\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "A possible solution is to use a dictionary. Please note that sometimes in pandas you can find strange characters, in particular the '\\xa0' character that you have to remove as in this example. This seems to be a common problem in pandas dataframes, see for example this link https://stackoverflow.com/questions/55442727/remove-unicode-xa0-from-pandas-column    \n",
    "```python\n",
    "df = df.rename(columns={\"Company\\xa0\\n(Maker-if known)\": \"Company\",\n",
    "                        \"Specific Bean Origin\\nor Bar Name\": \"Spec_Bean_Origin_or_Bar_Name\",\n",
    "                        \"Review\\nDate\": \"Review_Date\",\n",
    "                        \"Cocoa\\nPercent\": \"Cocoa_Percent\",\n",
    "                        \"Company\\nLocation\": \"Company_Location\",\n",
    "                        \"Bean\\nType\": \"Bean_Type\",\n",
    "                        \"Broad Bean\\nOrigin\": \"Broad_Bean_Origin\"\n",
    "                       })\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put here your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** \n",
    "\n",
    "Use the pandas data frame function info() is used in order to quickly check which data types are available and if data is missing. Do you note something strange?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "When looking at the missing values, only the features Broad_Bean_Origin and Bean_Type are containing one missing value out of 1795 total samples. However, when looking at the data frame head, the first five rows of feature Bean_Type are empty and should be therefore count as missing value. \n",
    "    \n",
    "Since we don't know exactly what is the content of the first entry Bean_Type, we can fetched it in order to check its value and to use this for replacing these values with NaN.\n",
    "\n",
    "```python\n",
    "    \n",
    "    missing_val_indication_bean_type = df.Bean_Type.values[0]\n",
    "\n",
    "    def replace_with_nan(missing_val_indication, current_val):\n",
    "    if current_val == missing_val_indication:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return current_val\n",
    "\n",
    "    # replace missing value of Bean_Type with np.nan\n",
    "    df[\"Bean_Type\"] = df[\"Bean_Type\"].apply(lambda x: \n",
    "                                        replace_with_nan(missing_val_indication_bean_type, x))\n",
    "```    \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "Find all categorical features.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python    \n",
    "    # get list of categorical features\n",
    "    list_categorical_cols = list(df.columns[df.dtypes == np.object])\n",
    "``` \n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "Find all numerical features\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python    \n",
    "    # get list of numerical features\n",
    "    list_numerical_cols = list(df.columns[df.dtypes != np.object])\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "Try to produce the following dataframe\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>numbers</th>\n",
    "      <th>nums</th>\n",
    "      <th>colors</th>\n",
    "      <th>other_column</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>#23</td>\n",
    "      <td>23</td>\n",
    "      <td>green</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>#24</td>\n",
    "      <td>24</td>\n",
    "      <td>red</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>#18</td>\n",
    "      <td>18</td>\n",
    "      <td>yellow</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>#14</td>\n",
    "      <td>14</td>\n",
    "      <td>orange</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>#12</td>\n",
    "      <td>NaN</td>\n",
    "      <td>purple</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>#10</td>\n",
    "      <td>XYZ</td>\n",
    "      <td>blue</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>#35</td>\n",
    "      <td>35</td>\n",
    "      <td>pink</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python    \n",
    "df = pd.DataFrame({\"numbers\": [\"#23\", \"#24\", \"#18\", \"#14\", \"#12\", \"#10\", \"#35\"],\n",
    "                   \"nums\": [\"23\", \"24\", \"18\", \"14\", np.nan, \"XYZ\", \"35\"],\n",
    "                   \"colors\": [\"green\", \"red\", \"yellow\", \"orange\", \"purple\", \"blue\", \"pink\"],\n",
    "                   \"other_column\": [0, 1, 0, 2, 1, 0, 2]})\n",
    "df\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "What would happen if we wanted to try and compute the mean of numbers?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "```python    \n",
    "df[\"numbers\"].mean()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:**\n",
    "\n",
    "Is there anything wrong with the previous question? Why? How can you solve the error?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "You have first of all convert all the string like '#32' into numbers.    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more realistic dataset for credit risk example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>default_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>105111</td>\n",
       "      <td>71</td>\n",
       "      <td>Employed</td>\n",
       "      <td>44245</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>176186</td>\n",
       "      <td>36</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>89675</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>160161</td>\n",
       "      <td>23</td>\n",
       "      <td>Employed</td>\n",
       "      <td>207251</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BB</td>\n",
       "      <td>106071</td>\n",
       "      <td>63</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>53904</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>32744</td>\n",
       "      <td>71</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>14698</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAA</td>\n",
       "      <td>104120</td>\n",
       "      <td>65</td>\n",
       "      <td>Employed</td>\n",
       "      <td>165566</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CCC</td>\n",
       "      <td>78300</td>\n",
       "      <td>34</td>\n",
       "      <td>Employed</td>\n",
       "      <td>30290</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D</td>\n",
       "      <td>15262</td>\n",
       "      <td>19</td>\n",
       "      <td>Employed</td>\n",
       "      <td>8939</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AA</td>\n",
       "      <td>169092</td>\n",
       "      <td>30</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>142462</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CC</td>\n",
       "      <td>49753</td>\n",
       "      <td>29</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>27251</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating  income  age employment_status  loan_amount default_history\n",
       "0     AA  105111   71          Employed        44245              No\n",
       "1    AAA  176186   36     Self-Employed        89675              No\n",
       "2    AAA  160161   23          Employed       207251              No\n",
       "3     BB  106071   63     Self-Employed        53904              No\n",
       "4      C   32744   71        Unemployed        14698              No\n",
       "5    AAA  104120   65          Employed       165566              No\n",
       "6    CCC   78300   34          Employed        30290              No\n",
       "7      D   15262   19          Employed         8939             Yes\n",
       "8     AA  169092   30        Unemployed       142462              No\n",
       "9     CC   49753   29     Self-Employed        27251             Yes"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define rating categories and their default probabilities\n",
    "rating_categories = {\n",
    "    \"AAA\": {\"default_prob\": 0.01, \"income_range\": (100000, 200000), \"loan_range\": (50000, 300000)},\n",
    "    \"AA\": {\"default_prob\": 0.02, \"income_range\": (90000, 180000), \"loan_range\": (40000, 250000)},\n",
    "    \"A\": {\"default_prob\": 0.03, \"income_range\": (80000, 160000), \"loan_range\": (35000, 200000)},\n",
    "    \"BBB\": {\"default_prob\": 0.05, \"income_range\": (60000, 140000), \"loan_range\": (30000, 150000)},\n",
    "    \"BB\": {\"default_prob\": 0.10, \"income_range\": (40000, 120000), \"loan_range\": (20000, 100000)},\n",
    "    \"B\": {\"default_prob\": 0.15, \"income_range\": (30000, 100000), \"loan_range\": (15000, 80000)},\n",
    "    \"CCC\": {\"default_prob\": 0.25, \"income_range\": (25000, 80000), \"loan_range\": (10000, 60000)},\n",
    "    \"CC\": {\"default_prob\": 0.35, \"income_range\": (20000, 70000), \"loan_range\": (8000, 40000)},\n",
    "    \"C\": {\"default_prob\": 0.50, \"income_range\": (15000, 50000), \"loan_range\": (5000, 20000)},\n",
    "    \"D\": {\"default_prob\": 0.80, \"income_range\": (10000, 30000), \"loan_range\": (2000, 10000)},\n",
    "}\n",
    "\n",
    "# Generate the dataset with improved consistency\n",
    "num_samples = 10\n",
    "ratings = list(rating_categories.keys())\n",
    "\n",
    "df_consistent_credit_risk = pd.DataFrame()\n",
    "\n",
    "# Generate data row by row ensuring consistency\n",
    "for _ in range(num_samples):\n",
    "    rating = np.random.choice(ratings)  # Select a credit rating\n",
    "    rating_info = rating_categories[rating]\n",
    "\n",
    "    income = np.random.randint(*rating_info[\"income_range\"])  # Income based on rating\n",
    "    loan_amount = np.random.randint(*rating_info[\"loan_range\"])  # Loan based on rating\n",
    "    age = np.random.randint(18, 75)  # Random age\n",
    "    employment_status = np.random.choice([\"Employed\", \"Unemployed\", \"Self-Employed\"])\n",
    "\n",
    "    # Default history based on rating's probability\n",
    "    default_history = np.random.choice([\"Yes\", \"No\"], p=[rating_info[\"default_prob\"], 1 - rating_info[\"default_prob\"]])\n",
    "\n",
    "    # Append row to DataFrame\n",
    "    df_consistent_credit_risk = pd.concat([df_consistent_credit_risk, \n",
    "        pd.DataFrame([[rating, income, age, employment_status, loan_amount, default_history]], \n",
    "                     columns=[\"rating\", \"income\", \"age\", \"employment_status\", \"loan_amount\", \"default_history\"])])\n",
    "\n",
    "# Reset index\n",
    "df_consistent_credit_risk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_consistent_credit_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEB**\n",
    "\n",
    "**Abhyankar Ameya**, \"*Exploring Risk Analytics using PCA with Python*\", [Medium](https://abhyankar-ameya.medium.com/exploring-risk-analytics-using-pca-with-python-3aca369cbfe4), data files for the interest rate example and further details about the python code can be dowloaded from the github repository of the author [here](https://github.com/Ameya1983/TheAlchemist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": "4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
